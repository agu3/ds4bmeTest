{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a8_q4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxin7vAQ2zgddvnRwTmF/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agu3/ds4bmeTest/blob/master/a8_q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcCgSFb2Itnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv6V4-lHMfVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shhs = pd.read_csv('shhs1.txt', sep = '\\t')\n",
        "shhs1 = shhs.dropna()\n",
        "\n",
        "shhs1['rdi4pNEW'] = [1 if x > 7 else 0 for x in shhs1['rdi4p']]\n",
        "shhs1 = shhs1.drop(columns = 'rdi4p')\n",
        "shhs1 = shhs1.drop(columns = 'pptid')\n",
        "shhs1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YLxw7WXI8z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = shhs1.sample(frac = 0.8, random_state = 0)\n",
        "test_dataset = shhs1.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PrUn0I00Jm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop('rdi4pNEW')\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f27iIkYQJVAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('rdi4pNEW')\n",
        "test_labels = test_dataset.pop('rdi4pNEW')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7rBmKvYSW2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJlyaWrqs1_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_test_data = normed_test_data.drop(columns = 'Staging5')\n",
        "normed_train_data = normed_train_data.drop(columns = 'Staging5')\n",
        "\n",
        "normed_test_data.isna().sum()\n",
        "normed_train_data.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSSwRNllUpCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation = 'relu', input_shape = (normed_train_data.shape[0], normed_test_data.shape[1])),\n",
        "  tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(32, activation = 'sigmoid'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss = 'mse',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCrTsw95WiQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "26ae555e-077f-41d4-c962-6cc549629a41"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_57 (Dense)             (None, 2318, 64)          1792      \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 2318, 64)          4160      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2318, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 2318, 32)          2080      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 2318, 32)          0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 2318, 1)           33        \n",
            "=================================================================\n",
            "Total params: 8,065\n",
            "Trainable params: 8,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYw15mo9YPhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "09a812c5-dcb1-4faf-e2a6-dac5f159fe57"
      },
      "source": [
        "history = model.fit(\n",
        "    normed_train_data, train_labels, epochs = 1000, validation_split = 0.2,\n",
        "    verbose = 0,\n",
        "    callbacks=[tfdocs.modeling.EpochDots()]\n",
        ")"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 2318, 27) for input Tensor(\"dense_57_input:0\", shape=(None, 2318, 27), dtype=float32), but it was called on an input with incompatible shape (None, 27).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 2318, 27) for input Tensor(\"dense_57_input:0\", shape=(None, 2318, 27), dtype=float32), but it was called on an input with incompatible shape (None, 27).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 2318, 27) for input Tensor(\"dense_57_input:0\", shape=(None, 2318, 27), dtype=float32), but it was called on an input with incompatible shape (None, 27).\n",
            "\n",
            "Epoch: 0, accuracy:0.5431,  loss:0.3692,  val_accuracy:0.6961,  val_loss:0.1962,  \n",
            "....................................................................................................\n",
            "Epoch: 100, accuracy:0.9288,  loss:0.0702,  val_accuracy:0.6509,  val_loss:0.2549,  \n",
            "....................................................................................................\n",
            "Epoch: 200, accuracy:0.9693,  loss:0.0372,  val_accuracy:0.6659,  val_loss:0.2703,  \n",
            "....................................................................................................\n",
            "Epoch: 300, accuracy:0.9871,  loss:0.0194,  val_accuracy:0.6573,  val_loss:0.2766,  \n",
            "....................................................................................................\n",
            "Epoch: 400, accuracy:0.9908,  loss:0.0160,  val_accuracy:0.6487,  val_loss:0.2860,  \n",
            "....................................................................................................\n",
            "Epoch: 500, accuracy:0.9908,  loss:0.0136,  val_accuracy:0.6530,  val_loss:0.2849,  \n",
            "....................................................................................................\n",
            "Epoch: 600, accuracy:0.9914,  loss:0.0135,  val_accuracy:0.6746,  val_loss:0.2812,  \n",
            "....................................................................................................\n",
            "Epoch: 700, accuracy:0.9930,  loss:0.0107,  val_accuracy:0.6595,  val_loss:0.2942,  \n",
            "....................................................................................................\n",
            "Epoch: 800, accuracy:0.9951,  loss:0.0103,  val_accuracy:0.6466,  val_loss:0.2926,  \n",
            "....................................................................................................\n",
            "Epoch: 900, accuracy:0.9995,  loss:0.0076,  val_accuracy:0.6422,  val_loss:0.3028,  \n",
            "...................................................................................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WIwIK-hptdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b7ff488e-8944-4791-b485-29c93a9ab74c"
      },
      "source": [
        "model.evaluate(normed_test_data, test_labels, verbose=2)"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 - 0s - loss: 0.3162 - accuracy: 0.6356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31620919704437256, 0.6355785727500916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l7ovPb3GTlP",
        "colab_type": "text"
      },
      "source": [
        "My test set accuracy using this neural network was  0.6356"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBZYK2GpG4sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import linear_model\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import ElasticNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4E8zkZ1HJYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shhs2 = pd.read_csv('shhs1.txt', sep = '\\t')\n",
        "shhs2 = shhs.dropna()\n",
        "\n",
        "shhs2['rdi4pNEW'] = [1 if x > 7 else 0 for x in shhs2['rdi4p']]\n",
        "shhs2 = shhs2.drop(columns = 'rdi4p')\n",
        "shhs2 = shhs2.drop(columns = 'pptid')\n",
        "shhs2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GJ_eH0QKQYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = shhs2.pop('rdi4pNEW')\n",
        "x = shhs2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30PSZCbAKkv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = make_regression(n_features = 29, random_state = 0)\n",
        "lg = ElasticNet(random_state = 0)\n",
        "lg.fit(x, y)\n",
        "print(lg.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8JiEXBNriK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = lg.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnIJBRinG8oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddbd6c1c-c74d-4a10-d0b1-e8af346588c6"
      },
      "source": [
        "lg.score(x, y)"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8798182406895314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMZy9CqIP6gR",
        "colab_type": "text"
      },
      "source": [
        "My test set accuracy using regression is 0.8798182406895314. For some reason, this is higher than my test set accuracy using the neural network. I think it's highly likely that I overfit my model to the training data, but I'm not sure where that might have happened. "
      ]
    }
  ]
}